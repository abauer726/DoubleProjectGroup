---
title: "131 Project Final Draft"
author: "Anna Bauer, Grant Cai, Alexis Navarra"
date: "3/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction


For this machine learning project, we chose to explore Spotify music and what makes a song popular because we all listen to music frequently and have specific genres that we enjoy. Something we’ve always wondered about is why we enjoy a particular song. Is it the artist singing the song, the fact that we’ve heard it on the radio, the beats per minute, or is it whether the lyrics are explicit? To come up with a solution to these questions, our goal is to get to know our data thoroughly, create visualizations of the attributes of our question, run regression models to find which attributes are most relevant, select and fine tune a model, and convey our results in an easily understandable report. This brings us to our research question: can we predict a song’s popularity based on its attributes? 



## Loading Data and Packages


The first step of our machine learning project is simple: find a data set. Only it was not quite as simple as we anticipated. We went through a multitude of datasets to find a dataset that did not face us with problems such as too many missing values, too many observations, too little observations, and more. This process took much longer than we expected, as it comprised of downloading multiple files and attempting to upload them into git, only to discover that they didn't satisfy all of our data needs to explore our research question.

Finally, we landed on a dataset from a Kaggle project called “Music Recommendation System using Spotify Dataset”, for which a codebook is attached in our zip files.  Below, we provide the list of general packages we used for this project (model-specific packages will be included in the model-building section), along with a preview of our dataset. 


```{r cars}
# list all packages here
library(tidyverse)
library(knitr)
library(lubridate)
library(httpuv)
library(cluster)
library(factoextra)
library(data.table)
library(dplyr)
library(ggplot2)

# load music.csv
music <- read.csv("/Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")

# music.csv preview
head(music)
```



## Data Pre-processing


In our initial look at this dataset, we wanted to identify any concerns early on so that we could either address them in our data pre-processing or look for a new dataset if the concerns were too large to overcome. The first problem in our data we looked for was missing values. After running a summary of the dataset, we found that there were no NA values, which we took as a good sign. We did notice that some of the 'release_date' values only contained the release year and not the exact release data of the song, but we figured this would not be a problem for our exploration. Additionally, we were thrown off by the number of zero values we saw in our initial look at the data, specifically in the columns 'explicit' and 'mode', but after further examination, we realized that they were coded dummy variables, so this was not a problem for our exploration. We also determined that we did not want to drop either of these variables from our data set, as we felt that if a song is explicit or not could be influential in how popular it becomes, and we felt that if a song was in a minor key or a major key could also be influential in how popular it becomes.


Thus, we begin our data pre-processing by mutating our dummy variables 'explicit' and 'mode' into as.factor variables. If, for a given song, explicit = 0, we label that as "Clean", and if explicit = 1, we label that "Explicit". If, for a given song, mode = 0, we label that as "Minor", and if mode = 1, we label that as "Major". 


```{r}
# mutate our dummy variables into as.factor
music = music %>% 
  mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>% 
  mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
```


As our research question requires us to take a regression approach, we did have a concern of our data having too many categorical variables to fit into our regressive model with this data. To address this problem, we thought about what variables would be most important to our data exploration. One of the variables that we thought would be most important to include was 'artists', as we know that the artist of a song can have a direct impact on the song's popularity: a more popular artist is more likely to release a song that has higher popularity, and vice versa. With the 'artists' column being string-valued categorical observations, and with there being so many different artists in our data, we wanted to find a way to incorporate this variable into our data as a unique but quantitative variable. We decided that this would be the next step of our data mutation


In order to keep the important variable of 'artists' but make it quantitative, we decided to take the average song popularity by each artist in the data, and assign that variable of average artist popularity to each artist as a new variable in the dataset. Thus, our dataset would lose the column 'artists' containing each artist's name, and instead assign the variable 'avg_art_pop' as the artist's average song popularity. This variable mutation process is outlined in the code chunk below.


```{r}
## manipulation of 'artist' variable

# create a new table that aggregates the variables popularity and artists and finds the mean song popularity for each given artist
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)

# merges the table above into our music dataset by artist
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)

# rename full dataset and x column
full_data <- rename(full_merge, avg_art_pop = x)

# delete previous 'artist' column
delete1 <- c("artists")
full_data <- full_data[!(names(full_data) %in% delete1)]
head(full_data)
```


In addressing the multiple categorical variables we had left in our dataset, we then set out to determine if these variables would be important to our exploration and if they would be feasible to incorporate quantitatively into our data (similar to 'artists' above). The qualitative variables that we had left in our dataset (that we decided would be irrational to dummy code) were "id", "key", "name", "release_date". We discussed each of these variables as a group, and decided that none of them would be very useful to try and fit quantitatively into our final data set, as we don't feel they will logically be important in predicting a given song's average popularity. Thus, we decided to drop these variables from our dataset, as shown below.


```{r}
# delete variables that will not be useful in our exploration
delete2 <- c("id", "key", "name", "release_date")
full_data <- full_data[!(names(full_data) %in% delete2)]
```


And finally, after making sure that all of our quantitative variables were numeric (shown in code chunk below), our data was ready for some exploratory data analysis. 


```{r}
# mutating leftover int variables to num type
full_data$popularity <- as.numeric(full_data$popularity)
full_data$year <- as.numeric(full_data$year)
full_data$duration_ms <- as.numeric(full_data$duration_ms)
```



## Exploratory Data Analysis
- response variable distribution chart
- figure of EDA plots
- correlation matrix and heatmap