---
title: "131projectfile"
output: html_document
---

```{r, echo=FALSE}
library(spotifyr)
library(tidyverse)
library(tidymodels)
library(knitr)
library(lubridate)
library(httpuv)
library(cluster)
library(factoextra)
library(data.table)
library(dplyr)
library(ggplot2)
library(BART)
library(gbm)
library(kknn)
library(earth)
library(caret)
library(FNN)
library("ggpubr")
theme_set(
  theme_bw() +
    theme(legend.position = "top")
  )
```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
music <- read.csv("/Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")

View(music)


# New research question: can we predict if a song will be a hit based on its attributes? Response variable: song.hotttnesss 
# anna path name: /Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv
```

```{r}
# randomly subset syntax, with 100 points (couldnt run this due to the file not loading)

# anna path name music: /Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv
# anna path name music w genre: /Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv


# grant path name music: /Users/Grant/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv
# grant path name music w genre: /Users/Grant/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv

# lex path name music: /Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv
# lex path name music w genre: /Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv
```


```{r}
# creating a new numeric variable for specific artist average popularity
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)

full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)

full_data <- rename(full_merge, avg_art_pop = x)
```

```{r}
set.seed((666))
# sample data to use for exploratory graphics
sample <- full_data[sample(nrow(full_data), 200), ]
```

```{r pressure, echo=T}
# some EDA plots to decide which predictor to add into our recipe
valence <- ggplot(sample, aes(x=valence, y=popularity)) + geom_point()
valence

year <- ggplot(sample, aes(x=year, y = popularity)) + geom_point()
year

acousticness <- ggplot(sample, aes(x=acousticness, y=popularity)) + geom_point()
acousticness

danceability <- ggplot(sample, aes(x=danceability, y=popularity)) + geom_point()
danceability

duration <- ggplot(sample, aes(x=duration_ms, y=popularity)) + geom_point()
duration

energy <- ggplot(sample, aes(x=energy, y=popularity)) + geom_point()
energy

explicit <- ggplot(sample, aes(x=explicit)) + geom_bar() + scale_x_continuous(breaks = c(0,1), labels=c("0" = "Clean", "1" = "Explicit"))
explicit

instrumentalness <- ggplot(sample, aes(x=instrumentalness, y=popularity)) + geom_point()
instrumentalness

key <- ggplot(sample, aes(x=key)) + geom_bar() + scale_x_continuous(breaks=0:11,
              labels=c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))
key

liveness <- ggplot(sample, aes(x=liveness, y=popularity)) + geom_point()
liveness

loudness <- ggplot(sample, aes(x=loudness, y=popularity)) + geom_point()
loudness

mode <- ggplot(sample, aes(x=mode)) + geom_bar() + scale_x_continuous(breaks=0:1,
              labels=c("Minor", "Major"))
mode

speechiness <- ggplot(sample, aes(x=speechiness, y=popularity)) + geom_point()
speechiness

tempo <- ggplot(sample, aes(x=tempo, y=popularity)) + geom_point()
tempo

avg_art_pop <- ggplot(sample, aes(x=avg_art_pop, y=popularity)) + geom_point()
avg_art_pop

# columns not included = artists, id, name, release_date
```

```{r}
figure <- ggarrange(tempo, speechiness, explicit,
                    ncol = 2, nrow = 2)
figure


```

```{r}
# modifying our full data to leave out the variables we don't want
full_data$popularity <- as.numeric(full_data$popularity)
full_data$year <- as.numeric(full_data$year)
full_data$duration_ms <- as.numeric(full_data$duration_ms)


full_data2 = full_data %>% 
  mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>% 
  mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))

delete <- c("artists", "id", "key", "name", "release_date")
full_data <- full_data[!(names(full_data) %in% delete)]
```

```{r}
# split training and testing data

#set seed
set.seed(123)
# Sample 700 observations as training data 
trainsample = sort(sample(nrow(full_data), nrow(full_data)*.7))
# define dat.train as the 700 observstions 
train = full_data[trainsample,]
# The rest as test data
test = full_data[-trainsample,]
```


```{r}
Ytrain <- train %>% select(popularity) %>% scale(center = TRUE, scale = TRUE)# from lab 5
Xtrain <- train %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)

Ytest <- test$popularity
Xtest <- test %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)

do.chunk <- function(chunkid, folddef, Xdat, Ydat){
  train = (folddef!= chunkid)
  
  Xtr = Xdat[train,]
  Ytr = Ydat[train]
  
  Xval = Xdat[!train,]
  Yval = Ydat[!train]
  
  predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, ...)
  predYvl = knn(train = Ytr, test = Xval, cl = Ytr, ...)
  
  data.frame(fold = chunkid,
             train.error = mean(predYtr != Ytr),
             val.error = mean(predYval != Yval))
}
```

```{r}
## this is cross validation from the lab - not going to use
#nfold = 10 
#set.seed(100)
#folds = cut(1:nrow(train), breaks = nfold, labels = FALSE) %>% sample()
#folds
```

```{r}
# this is the other guys method of getting cross validation
train_folds <- vfold_cv(train, v=10, repeats = 5)
```

```{r}
# make recipe (from homeboy's code, don't think it's necessary anymore)
recipe <- recipe(
  popularity ~ ., data = train) %>%
  step_dummy(mode, explicit, one_hot = TRUE) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
recipe
```

```{r}
# save progress thus far
# /Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv
save(train_folds, recipe, train, file = "/Users/Grant/DoubleProjectGroup/131 Project/Spotify Dataset/model_setup.rda")
```

```{r}
## KNN regression work from lab 2
# load libraries
library(ISLR)
library(tidyverse)
library(class)
library(FNN)

# train knn regressor  and make predictions on training set using k=2
pred.Ytrain = knn.reg(train = Xtrain, test = Xtrain, y = Ytrain)
head(pred.Ytrain)
# get training MSE
mean((pred.Ytrain$pred - Ytrain)^2)

# now make predictions on test set
pred.Ytest = knn.reg(train = Xtrain, test = Xtest, y = Ytrain, k = 2)
head((pred.Ytest$pred - Ytest)^2)
mean((pred.Ytest$pred - Ytest)^2)
```

```{r}
## homeboy's KNN code
knn_model <- 
  nearest_neighbor(
    neighbors = tune(),
    mode = "regression") %>% 
  set_engine("kknn")

knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(recipe)

# set-up tuning grid ----
knn_params <- parameters(knn_model)

# define grid
knn_grid <- grid_regular(knn_params, levels = 2)

# tune and fit repeated cross fold validation
knn_tune <- knn_workflow %>% 
  tune_grid(
    # what will it fit the workflow to
    resamples = train_folds, 
    # how does it complete the models in those workflows
    grid = knn_grid)

#save(knn_tune, knn_workflow, file = "/Users/Grant/DoubleProjectGroup/131 Project/Spotify Dataset/knn_tune.rda")
```

```{r}
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)

# X and Y training datasets as matrix
Xtrain %>% as.matrix()
Ytrain %>% as.matrix()

# model building on training sets
control <- trainControl(method = "repeatedcv", 
                        number = 5, 
                        repeats = 5, 
                        search = "random", 
                        verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain, Ytrain),
                       method = "glmnet",
                       preProcess = c("center", "scale"),
                       tuneLength = 25,
                       trControl = control)
elastic_model
```

```{r}
# elastic model prediction on test data
elastic.pred <- predict(elastic_model, Xtest)
elastic.pred
# plot
plot(elastic_model, main = "Elastic Net Regression")
```

```{r}
# BART Implementation
set.seed (1)
bartfit <- gbart(Xtrain , Ytrain , x.test = Xtest)
```

```{r}
Yhat.bart <- bartfit$yhat.test.mean
mean ((Ytest - Yhat.bart)^2) # test error
```

```{r}
# How many times each variable appeared in the collection of trees
ord <- order(bartfit$varcount.mean , decreasing = T)
bartfit$varcount.mean[ord]
```

```{r}
# This doesn't work
bart_workflow <- workflow() %>% 
  add_model(bartfit) %>% 
  add_recipe(recipe)
```

```{r}
# Test error was quite high for BART, checking if boosting is any better....
set.seed (1)
boost.music <- gbm(popularity ~ ., data = train,
  distribution = "gaussian", n.trees = 1000,
  interaction.depth = 4)
```

```{r}
yhat.boost <- predict(boost.music ,
  newdata = train, n.trees = 1000)
mean ((yhat.boost - Ytest)^2)
```


```{r}

trainmars <- train
# implementation of MARS method
# divide dataset into k pieces
# fit a regression model to each piece
# use k-fold cross validation to choose a value for k
# using train


#create a tuning grid
hyper_grid <- expand.grid(degree = 1:3,
                          nprune = seq(2, 50, length.out = 10) %>%
                          floor())

#make this example reproducible
set.seed(1)

#fit MARS model using k-fold cross-validation
cv_mars <- train(
  x = subset(trainmars, select = -c(popularity)),
  y = train$popularity,
  method = "earth",
  metric = "RMSE",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = hyper_grid)
```

```{r}
#display model with lowest test RMSE
cv_mars$results %>%
  filter(nprune= cv_mars$bestTune$nprune, degree = cv_mars$bestTune$degree)    

#display test RMSE by terms and degree
ggplot(cv_mars)

```

