avg_art_pop <- ggplot(sample, aes(x=avg_art_pop, y=popularity)) + geom_point(col = "deepskyblue") + geom_smooth(se = FALSE, color = "black")
# variables not included as plots = artists, id, name, release_date
# trying to put
figure <- ggarrange(valence, year, acousticness, danceability, duration, energy, explicit, instrumentalness, key, liveness, loudness, mode, speechiness, tempo, avg_art_pop, ncol = 3, nrow = 5)
figure
knitr::opts_chunk$set(echo = TRUE)
# list all packages here
# load music.csv
music <- read.csv("/Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")
# music.csv preview
music.head()
head(music)
music = music %>%
mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>%
mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
# list all packages here
library(tidyverse)
library(knitr)
library(lubridate)
library(httpuv)
library(cluster)
library(factoextra)
library(data.table)
library(dplyr)
library(ggplot2)
# load music.csv
music <- read.csv("/Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")
# music.csv preview
head(music)
music = music %>%
mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>%
mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain %>% as.matrix()
music <- read.csv("/Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")
# New research question: can we predict if a song will be a hit based on its attributes? Response variable: song.hotttnesss
# anna path name: /Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv
# creating a new numeric variable for specific artist average popularity
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
full_data <- rename(full_merge, avg_art_pop = x)
# making some of the int variables into numeric
full_data$popularity <- as.numeric(full_data$popularity)
full_data$year <- as.numeric(full_data$year)
full_data$duration_ms <- as.numeric(full_data$duration_ms)
# mutating dummy variables
full_data2 = full_data %>%
mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>%
mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
# modifying our full data to leave out the variables we don't want
delete <- c("artists", "id", "key", "name", "release_date")
full_data <- full_data[!(names(full_data) %in% delete)]
# split training and testing data
#set seed
set.seed(123)
# Sample 700 observations as training data
trainsample = sort(sample(nrow(full_data), nrow(full_data)*.7))
# define dat.train as the 700 observstions
train = full_data[trainsample,]
# The rest as test data
test = full_data[-trainsample,]
# split training and testing data
#set seed
set.seed(123)
# Sample 700 observations as training data
trainsample = sort(sample(nrow(full_data), nrow(full_data)*.7))
# define dat.train as the 700 observstions
train = full_data[trainsample,]
# The rest as test data
test = full_data[-trainsample,]
Ytrain <- train$popularity %>% scale(center = TRUE, scale = TRUE)# from lab 5
Xtrain <- train %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
Ytest <- test$popularity %>% scale(center = TRUE, scale = TRUE)
Xtest <- test %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
# do.chunk <- function(chunkid, folddef, Xdat, Ydat){
#   train = (folddef!= chunkid)
#
#   Xtr = Xdat[train,]
#   Ytr = Ydat[train]
#
#   Xval = Xdat[!train,]
#   Yval = Ydat[!train]
#
#   predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, ...)
#   predYvl = knn(train = Ytr, test = Xval, cl = Ytr, ...)
#
#   data.frame(fold = chunkid,
#              train.error = mean(predYtr != Ytr),
#              val.error = mean(predYval != Yval))
# }
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain %>% as.matrix()
Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1, # 1 is less accurate but faster output
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain, Ytrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain %>% as.matrix()
Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1, # 1 is less accurate but faster output
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain, Ytrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
# creating a new numeric variable for specific artist average popularity
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
full_data <- rename(full_merge, avg_art_pop = x)
# making some of the int variables into numeric
full_data$popularity <- as.numeric(full_data$popularity)
full_data$year <- as.numeric(full_data$year)
full_data$duration_ms <- as.numeric(full_data$duration_ms)
# mutating dummy variables
full_data2 = full_data %>%
mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>%
mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
# modifying our full data to leave out the variables we don't want
delete <- c("artists", "id", "key", "name", "release_date")
full_data <- full_data[!(names(full_data) %in% delete)]
# split training and testing data
#set seed
set.seed(123)
# Sample 700 observations as training data
trainsample = sort(sample(nrow(full_data), nrow(full_data)*.7))
# define dat.train as the 700 observstions
train = full_data[trainsample,]
# The rest as test data
test = full_data[-trainsample,]
Ytrain <- train$popularity %>% scale(center = TRUE, scale = TRUE)# from lab 5
Xtrain <- train %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
Ytest <- test$popularity %>% scale(center = TRUE, scale = TRUE)
Xtest <- test %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
# do.chunk <- function(chunkid, folddef, Xdat, Ydat){
#   train = (folddef!= chunkid)
#
#   Xtr = Xdat[train,]
#   Ytr = Ydat[train]
#
#   Xval = Xdat[!train,]
#   Yval = Ydat[!train]
#
#   predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, ...)
#   predYvl = knn(train = Ytr, test = Xval, cl = Ytr, ...)
#
#   data.frame(fold = chunkid,
#              train.error = mean(predYtr != Ytr),
#              val.error = mean(predYval != Yval))
# }
library(spotifyr)
library(tidyverse)
library(tidymodels)
library(knitr)
library(lubridate)
library(httpuv)
library(cluster)
library(factoextra)
library(data.table)
library(dplyr)
library(ggplot2)
library(BART)
library(gbm)
library(kknn)
library(earth)
library(caret)
library(FNN)
library("ggpubr")
theme_set(
theme_bw() +
theme(legend.position = "top")
)
music <- read.csv("/Users/lexnavarra/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/musicdata.csv")
# New research question: can we predict if a song will be a hit based on its attributes? Response variable: song.hotttnesss
# anna path name: /Users/kimbauer/Desktop/DoubleProjectGroup/131 Project/Spotify Dataset/data_w_genres.csv
# creating a new numeric variable for specific artist average popularity
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
full_data <- rename(full_merge, avg_art_pop = x)
# making some of the int variables into numeric
full_data$popularity <- as.numeric(full_data$popularity)
full_data$year <- as.numeric(full_data$year)
full_data$duration_ms <- as.numeric(full_data$duration_ms)
# mutating dummy variables
full_data2 = full_data %>%
mutate(explicit = as.factor(ifelse(explicit == 0, "Clean", "Explicit"))) %>%
mutate(mode = as.factor(ifelse(mode == 0, "Minor", "Major")))
# modifying our full data to leave out the variables we don't want
delete <- c("artists", "id", "key", "name", "release_date")
full_data <- full_data[!(names(full_data) %in% delete)]
# split training and testing data
#set seed
set.seed(123)
# Sample 700 observations as training data
trainsample = sort(sample(nrow(full_data), nrow(full_data)*.7))
# define dat.train as the 700 observstions
train = full_data[trainsample,]
# The rest as test data
test = full_data[-trainsample,]
Ytrain <- train$popularity %>% scale(center = TRUE, scale = TRUE)# from lab 5
Xtrain <- train %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
Ytest <- test$popularity %>% scale(center = TRUE, scale = TRUE)
Xtest <- test %>% select(-popularity) %>% scale(center = TRUE, scale = TRUE)
# do.chunk <- function(chunkid, folddef, Xdat, Ydat){
#   train = (folddef!= chunkid)
#
#   Xtr = Xdat[train,]
#   Ytr = Ydat[train]
#
#   Xval = Xdat[!train,]
#   Yval = Ydat[!train]
#
#   predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, ...)
#   predYvl = knn(train = Ytr, test = Xval, cl = Ytr, ...)
#
#   data.frame(fold = chunkid,
#              train.error = mean(predYtr != Ytr),
#              val.error = mean(predYval != Yval))
# }
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain %>% as.matrix()
Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5, # 5 fold
repeats = 5, # 5 repeats
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain, Ytrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) # our cross-validation defined above
Xtrain_mat <- Xtrain %>% as.matrix()
Ytrain_mat <-Ytrain %>% as.matrix()
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain_mat <- Xtrain %>% as.matrix()
Ytrain_mat <-Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5, # 5 fold
repeats = 5, # 5 repeats
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain_mat, Ytrain_mat),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) # our cross-validation defined above
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
Xtrain_mat <- Xtrain %>% as.matrix()
Ytrain_mat <-Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5, # 5 fold
repeats = 5, # 5 repeats
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain_mat, Ytrain_mat),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) # our cross-validation defined above
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
# Xtrain_mat <- Xtrain %>% as.matrix()
# Ytrain_mat <-Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5, # 5 fold
repeats = 5, # 5 repeats
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = cbind(Xtrain, Ytrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) # our cross-validation defined above
head(train)
## trying elastic net code
# load packages
library(dplyr)
library(glmnet)
library(ggplot2)
library(caret)
# X and Y training datasets as matrix
# Xtrain_mat <- Xtrain %>% as.matrix()
# Ytrain_mat <-Ytrain %>% as.matrix()
# model building on training sets
control <- trainControl(method = "repeatedcv",
number = 5, # 5 fold
repeats = 5, # 5 repeats
search = "random",
verboseIter = TRUE)
# training elastic net regression model
elastic_model <- train(popularity ~ ., data = train,
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) # our cross-validation defined above
elastic_model
# need to tune and cross-validate model
elastic_model
plot(elastic_model, main = "Elastic Net Regression")
# elastic model prediction on test data (to have prediction code)
elastic.pred <- predict(elastic_model, Xtest)
elastic.pred
# plot
plot(elastic_model, main = "Elastic Net Regression")
# lasso and ridge account for multi-collinearity, and elastic net is a combination of the two, so no need to investigate collinearity
elastic_model$bestTune
elastic_model$results %>%
filter(alpha == elastic_model$bestTune$alpha, lambda == elastic_model$bestTune$lambda)
elastic.pred <- predict(elastic_model, test)
elastic.pred
elastic_model <- train(x = el_X, y = el_Y
method = "glmnet",
elastic_model <- train(x = el_X, y = el_Y,
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
el_X <- model.matrix(popularity ~ ., train)[, -1]
el_Y <- train$popularity
elastic_model <- train(x = el_X, y = el_Y,
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
elastic_model$results %>%
filter(alpha == elastic_model$bestTune$alpha, lambda == elastic_model$bestTune$lambda)
el_X <- model.matrix(popularity ~ ., full_data)[, -1]
el_Y <- full_data$popularity
x.eltrain = el_X[train,]
eltrain = sort(sample(nrow(el_X), nrow(el_X)*.7))
eltest = (-eltrain)
x.eltrain = el_X[eltrain,]
x.eltrain = el_X[eltrain,]
y.eltrain = el_Y[eltrain]
x.eltest = el_X[eltest,]
y.eltest = el_Y[eltest]
elastic_model <- train(x = x.eltrain, y = x.eltrain,
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
elastic_model <- train(popularity ~.,
data = cbind(x.eltrain, y.eltrain)
method = "glmnet",
elastic_model <- train(popularity ~.,
data = cbind(x.eltrain, y.eltrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
elastic_model <- train(data = cbind(x.eltrain, y.eltrain),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control) #
elastic_model <- train(x = x.eltrain, y = y.eltrain),
elastic_model <- train(x = x.eltrain, y = y.eltrain,
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = control)
best_elastic <- elastic_model$results %>%
filter(alpha == elastic_model$bestTune$alpha, lambda == elastic_model$bestTune$lambda)
best_elastic
# elastic model prediction on test data (to have prediction code)
elastic.pred <- predict(elastic_model, x.eltest)
# compute RMSE of prediction on test data
# lasso and ridge account for multi-collinearity, and elastic net is a combination of the two, so no need to investigate collinearity
# elastic model prediction on test data (to have prediction code)
elastic.pred <- predict(elastic_model, x.eltest)
# evaluate mse on the test data
elastic_mse <- mean((elastic.pred - y.eltest)^2)
elastic_mse
# lasso and ridge account for multi-collinearity, and elastic net is a combination of the two, so no need to investigate collinearity
seq(3)
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
artist_pop_tale
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
head(artist_pop_table)
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
head(full_merge)
key <- ggplot(sample, aes(x=key)) + geom_bar(fill = "darkslategray3") + scale_x_continuous(breaks=0:11,
labels=c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))
key
key <- ggplot(sample, aes(x=key, y=popularity)) + geom_bar(fill = "darkslategray3") + scale_x_continuous(breaks=0:11,
labels=c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))
key
# some EDA plots
valence <- ggplot(sample, aes(x=valence, y=popularity)) + geom_point(color = "seagreen1") + geom_smooth(se = FALSE, color = "black")
year <- ggplot(sample, aes(x=year, y = popularity)) + geom_point(color = "dodgerblue2") + geom_smooth(se = FALSE, color = "black")
acousticness <- ggplot(sample, aes(x=acousticness, y=popularity)) + geom_point(col = "mediumpurple1")
danceability <- ggplot(sample, aes(x=danceability, y=popularity)) + geom_point(col = "lightpink") + geom_smooth(se = FALSE, color = "black")
duration <- ggplot(sample, aes(x=duration_ms, y=popularity)) + geom_point(col = "sienna1")
energy <- ggplot(sample, aes(x=energy, y=popularity)) + geom_point(col = "firebrick3") + geom_smooth(se = FALSE, color = "black")
explicit <- ggplot(sample, aes(x=explicit)) + geom_bar(fill = "darkseagreen") + scale_x_continuous(breaks = c(0,1), labels=c("0" = "Clean", "1" = "Explicit"))
instrumentalness <- ggplot(sample, aes(x=instrumentalness, y=popularity)) + geom_point(col = "goldenrod1")
key <- ggplot(sample, aes(x=key)) + geom_bar(fill = "darkslategray3") + scale_x_continuous(breaks=0:11,
labels=c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))
key
liveness <- ggplot(sample, aes(x=liveness, y=popularity)) + geom_point(col = "deeppink1")
loudness <- ggplot(sample, aes(x=loudness, y=popularity)) + geom_point(col = "khaki1") + geom_smooth(se = FALSE, color = "black")
mode <- ggplot(sample, aes(x=mode)) + geom_bar(fill = "plum") + scale_x_continuous(breaks=0:1,
labels=c("Minor", "Major"))
speechiness <- ggplot(sample, aes(x=speechiness, y=popularity)) + geom_point(col = "green4") + geom_smooth(se = FALSE, color = "black")
tempo <- ggplot(sample, aes(x=tempo, y=popularity)) + geom_point(col = "springgreen")
avg_art_pop <- ggplot(sample, aes(x=avg_art_pop, y=popularity)) + geom_point(col = "deepskyblue") + geom_smooth(se = FALSE, color = "black")
# variables not included as plots = artists, id, name, release_date
# some EDA plots
valence <- ggplot(sample, aes(x=valence, y=popularity)) + geom_point(color = "seagreen1") + geom_smooth(se = FALSE, color = "black")
year <- ggplot(sample, aes(x=year, y = popularity)) + geom_point(color = "dodgerblue2") + geom_smooth(se = FALSE, color = "black")
acousticness <- ggplot(sample, aes(x=acousticness, y=popularity)) + geom_point(col = "mediumpurple1")
danceability <- ggplot(sample, aes(x=danceability, y=popularity)) + geom_point(col = "lightpink") + geom_smooth(se = FALSE, color = "black")
duration <- ggplot(sample, aes(x=duration_ms, y=popularity)) + geom_point(col = "sienna1")
energy <- ggplot(sample, aes(x=energy, y=popularity)) + geom_point(col = "firebrick3") + geom_smooth(se = FALSE, color = "black")
explicit <- ggplot(sample, aes(x=explicit)) + geom_bar(fill = "darkseagreen") + scale_x_continuous(breaks = c(0,1), labels=c("0" = "Clean", "1" = "Explicit"))
instrumentalness <- ggplot(sample, aes(x=instrumentalness, y=popularity)) + geom_point(col = "goldenrod1")
key <- ggplot(sample, aes(x=key)) + geom_bar(fill = "darkslategray3") + scale_x_continuous(breaks=0:11,
labels=c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))
key
liveness <- ggplot(sample, aes(x=liveness, y=popularity)) + geom_point(col = "deeppink1")
loudness <- ggplot(sample, aes(x=loudness, y=popularity)) + geom_point(col = "khaki1") + geom_smooth(se = FALSE, color = "black")
mode <- ggplot(sample, aes(x=mode)) + geom_bar(fill = "plum") + scale_x_continuous(breaks=0:1,
labels=c("Minor", "Major"))
speechiness <- ggplot(sample, aes(x=speechiness, y=popularity)) + geom_point(col = "green4") + geom_smooth(se = FALSE, color = "black")
tempo <- ggplot(sample, aes(x=tempo, y=popularity)) + geom_point(col = "springgreen")
avg_art_pop <- ggplot(sample, aes(x=avg_art_pop, y=popularity)) + geom_point(col = "deepskyblue") + geom_smooth(se = FALSE, color = "black")
# variables not included as plots = artists, id, name, release_date
## manipulation of 'artist' variable
# create a new table that aggregates the variables popularity and artists and finds the mean song popularity for each given artist
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
# merges the table above into our music dataset by artist
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
# rename full dataset and x column
full_data <- rename(full_merge, avg_art_pop = x)
# drop previous 'artist' column
delete1 <- c("artists")
full_data <- full_data[!(names(full_data) %in% delete)]
## manipulation of 'artist' variable
# create a new table that aggregates the variables popularity and artists and finds the mean song popularity for each given artist
artist_pop_table <- aggregate(music$popularity, list(music$artists), FUN = mean)
# merges the table above into our music dataset by artist
full_merge <- merge(x = music, y = artist_pop_table, by.x = c("artists"), by.y = c("Group.1"), all.x = TRUE)
# rename full dataset and x column
full_data <- rename(full_merge, avg_art_pop = x)
# drop previous 'artist' column
delete1 <- c("artists")
full_data <- full_data[!(names(full_data) %in% delete1)]
head(full_data)
